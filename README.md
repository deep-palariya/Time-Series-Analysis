# Time-Series-Analysis
Time series analysis to visualize and  predicting using ARIMA method


# Time Series Analysis



## Time analysis is a method for analyzing data that is collected over time. The goal of time analysis is to understand the patterns and trends in the data, as well as any fluctuations or anomalies. This type of analysis is often used to study data related to time-based events, such as stock prices, weather patterns, sales data, or traffic data.

There are several methods used in time analysis, including:

-- Time series decomposition: Breaking down a time series into its components, such as trend, seasonality, and residuals.

-- Time series forecasting: Predictive modeling of future time-based events using historical data.

-- Trend analysis: Examining the overall direction of change in a time series over time.

-- Seasonality analysis: Identifying repeating patterns in a time series based on the time of year, such as monthly or quarterly patterns.

-- Anomaly detection: Identifying unusual or unexpected events in a time series.

## Time analysis techniques can be applied to various types of data, including financial data, economic data, and environmental data, among others. The choice of method depends on the nature of the data and the question being asked. Time analysis can help organizations make informed decisions by providing insights into patterns, trends, and future events.

### Some important terms:


-- Kernel Density Estimation (KDE) is a non-parametric statistical method used for estimating the probability density function (pdf) of a1. random variable. It is commonly used in time analysis to estimate the distribution of time-based data, such as time series data. The KDE method involves mapping the data to a smooth curve, which can then be used to make inferences about the underlying distribution of the data. The curve is generated by applying a smoothing kernel, such as a Gaussian kernel, to the data, which allows for estimation of the pdf even in the presence of noise or other disturbances in the data.



-- The normaltest function performs a statistical test to determine whether a data sample is likely to come from a normal (Gaussian) distribution.

The function takes an input array, residuals, and returns two outputs: stat and p. The stat value is a test statistic, and the p value is the p-value, which gives the probability that the residuals are drawn from a normal distribution.

The null hypothesis of the normality test is that the residuals come from a normal distribution. If the p-value is less than a certain significance level (usually 0.05), then the null hypothesis is rejected and it is concluded that the residuals do not come from a normal distribution. If the p-value is greater than the significance level, then the null hypothesis cannot be rejected and it is concluded that the residuals may come from a normal distribution.



-- autolag and AIC are concepts used in time series analysis.

autolag is a method for selecting the best lag value for an autoregressive (AR) model, which is a type of time series model used to make predictions based on past values. In an AR model, the prediction for the next value in the time series is based on a weighted sum of the previous p values. The value of p (the lag order) determines the number of previous values used to make the prediction. autolag is a method for automatically selecting the best value for p based on a statistical criterion, such as the Akaike Information Criterion (AIC).

AIC (Akaike Information Criterion) is a statistical criterion used to compare the quality of different time series models. It measures the goodness of fit of a model, taking into account both the accuracy of the model and the number of parameters in the model. The AIC value is calculated as the difference between the log likelihood of the model and the number of parameters in the model. The smaller the AIC value, the better the model. AIC can be used to select the best model from a set of candidate models.

In summary, autolag is a method for selecting the best lag order in an AR model, and AIC is a criterion for selecting the best time series model from a set of candidates. Both of these concepts are important in time series analysis for achieving accurate and reliable predictions.



